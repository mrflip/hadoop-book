<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">
<chapter id="flip">
  <title>Case Studies</title>
  <sect1>
    <title>Graph Analysis Chimpanzee Style</title>
    <para>Using Pig and Wukong to Explore Billion-edge Network Graphs</para>
    <sect2>
      <title>Basics</title>
      <para>Networks at massive scale are fascinating. It’s a very general model: you have things (that we’ll call nodes); they’re related (edges); and we can attach numbers or attributes to those things or relationships (node or edge metadata).</para>
      <para>For example, here are a few datasets that come up in a search for “network” on infochimps.org:</para>
      <itemizedlist>
        <listitem>
          <para>A social network, such as Twitter or Facebook. People are somewhat impersonally modeled as nodes, and relationships (<literal>@mrflip</literal> is friends with <literal>@tom_e_white</literal>) or actions (<literal>@infochimps</literal> mentioned <literal>@hadoop</literal>) as edges. The number of messages a user has sent and the bag of words from all those messages are each pieces of node metadata.</para>
        </listitem>
        <listitem>
          <para>A linked document collection such as Wikipedia or the entire web. Each page is a node (carrying its title, view count and categories as node metadata). Each hyperlink is an edge, and the frequency at which people click from one page to the next is edge metadata.</para>
        </listitem>
        <listitem>
          <para>The connections of neurons (nodes) and synapses (edges) in the <emphasis
              role="italic">C. elegans</emphasis> roundworm.<footnote>
              <para><ulink
                  url="http://infochimps.org/datasets/neuronal-wiring-network-of-the-caenorhabditis-elegans-roundworm"
                /></para>
            </footnote></para>
        </listitem>
        <listitem>
          <para>A highway map, with exits as nodes, and highway segments as edges. The Open Street Map project’s dataset has global coverage of place names (node metadata), street number ranges (edge metadata), and more.<footnote>
              <para><ulink url="http://www.openstreetmap.org/"/>, <ulink
                  url="http://infochimps.org/datasets/open-street-map"/></para>
            </footnote></para>
        </listitem>
      </itemizedlist>
      <para>Or more esoteric graphs that fall out when you take an interesting problem and shake it just right. Take a few million Twitter messages and, every time a non-keyboard character is used, emit an edge for every other such character in the message. Simply by saying “sometimes, when humans use 最, they often use 近” you can recreate a map of human languages (see <xref
          linkend="TwitterLanguageMap"/>).</para>
      <figure id="TwitterLanguageMap">
        <title>Twitter Language Map</title>
        <mediaobject>
          <imageobject>
            <imagedata fileref="diagrams/twitter_language_map-labels.png" format="PNG"/>
          </imageobject>
        </mediaobject>
      </figure>
      <para>What’s amazing about these organic network graphs is that given enough data, a growing collection of powerful tools are able to <emphasis
          role="italic">generically</emphasis> use this network structure to expose insight. For example, we’ve used variants of the same algorithm<footnote>
          <para>All are steady-state network flow problems. A huge number of random websurfers wandering through the linked-document collection will visit the most interesting pages most often. If you model social network interactions as exchanges of social capital, the steady-state flow of that capital will highlight the most interesting users. The year-to-year progress of students to higher or lower scores implies what each school’s effect on a generic class would be.</para>
        </footnote> to do each of:</para>
      <itemizedlist>
        <listitem>
          <para>Rank the most important pages in the Wikipedia linked-document collection. Google uses a vastly more refined version this approach to identify top search hits.</para>
        </listitem>
        <listitem>
          <para>Identify celebrities and experts in the Twitter social graph. Users who have many more followers than their “trstrank” would imply are often spammers.</para>
        </listitem>
        <listitem>
          <para>Predict a school’s impact on student education using millions of anonymized exam scores gathered over five years.</para>
        </listitem>
      </itemizedlist>
      <para>At Infochimps, we’ve got a whole bag of tricks ready to apply to any interesting network graph that comes into the collection. We chiefly use Pig (described in chapter XXXX) and Wukong (<ulink
          url="http://github.com/mrflip/wukong"
        />), a toolkit we've developed for Hadoop streaming in the Ruby programming language. They let use write simple scripts like the ones below—almost all of which fit on a single printed page—that capably process networks of 100 million nodes and 2 billion edges.</para>
    </sect2>
    <sect2>
      <title>Measuring Community</title>
      <para>The most interesting network in our collection is a massive crawl of the Twitter social graph. With more than 50 million nodes and 2 billion edges, it is a fantastic instrument for understanding what people talk about and how they relate to each other. Here are straightforward ways to characterize a twitter user’s community: </para>
      <itemizedlist>
        <listitem>
          <para>Who are the people they converse with (the @reply graph)?</para>
        </listitem>
        <listitem>
          <para>Do the people they engage with reciprocate that attention (symmetric links)?</para>
        </listitem>
        <listitem>
          <para>Among the user’s community, how many engage with each other (clustering coefficient)?</para>
        </listitem>
      </itemizedlist>
      <para>Here’s an exploration of these questions within the Twitter subuniverse of “People who talk about Infochimps or Hadoop”.<footnote>
          <para>In keeping with the ego-centered ethos of social networks, chosen without apology.</para>
        </footnote></para>
    </sect2>
    <sect2>
      <title>Everybody’s Talkin’ At Me: The Twitter Reply Graph</title>
      <para>Twitter lets you reply to another user’s message and thus engage in conversation. Since it’s an expressly public activity, a reply is a strong <emphasis
          role="italic"
        >social token</emphasis>: it shows interest in what the other is saying, and demonstrates that interest is worth re-broadcasting.</para>
      <para>The first step in our processing is done in Wukong, a Ruby language library for Hadoop. It lets us write small, agile programs capable of handling multi-terabyte data streams. Here is a snippet from the class that represents a twitter message:<footnote>
          <para>You may find full working source code on the book’s website.</para>
        </footnote></para>
      <programlisting>class Tweet &lt; Struct.new(:tweet_id, :screen_name, :created_at,
    :reply_tweet_id, :reply_screen_name, :text)
  def initialize(raw_tweet)
    # ... gory details of parsing raw tweet omitted
  end
  
  # Tweet is a reply if there's something in the reply_tweet_id slot
  def is_reply?
    not reply_tweet_id.blank?
  true
end</programlisting>
      <para>Anyone can pull gigabytes of data per day from Twitter’s streaming API: follow the instructions at <ulink
          url="http://dev.twitter.com/doc/get/statuses/sample"/> or use a tool like <ulink
          url="http://github.com/hayesdavis/flamingo"/>.</para>
      <para>Twitter messages typically arrive in raw JSON format. Here are a few tweets:</para>
      <literallayout><literal>{"id":3239897342,"screen_name":"tom_e_white","text":"Just finished the final draft for Hadoop: the Definitive Guide!","reply_screen_name":null,"reply_tweet_id":null,...}
{"id":3239873453,"screen_name":"mrflip","text":"@tom_e_white Can't wait to get a copy!","reply_screen_name":"tom_e_white","reply_tweet_id":3239897342,...}
{"id":3235751418,"screen_name":"drsm79","text":"Lots of ideas buzzing round my head but not quite crystalising, so can't sleep. Want to read Tom's hadoop book, too - thanks @tom_e_white!!","reply_screen_name":null,"reply_tweet_id":null,...}
{"id":16434069252,"screen_name":"wattsteve","text":"@josephkelly great job on the #InfoChimps API. Next time I come by remind me to tell you about the time a baboon broke into our house.","reply_screen_name":"josephkelly",...}
{"id":7809927173,"screen_name":"mrflip","text":"@mza Re: http://bit.ly/atbroxmr Have you seen @James_Rubino's http://bit.ly/clusterfork ? Lots of good hadoop refs there too","reply_screen_name":"@mza",...}
{"id":4491069515,"screen_name":"nealrichter","text":"@tlipcon divide lots of data into little parts.
Magic software gnomes fix up the parts, elves then assemble those into whole things
#hadoop","reply_screen_name":"tlipcon",...}</literal></literallayout>
      <para>Twitter populates the <literal>reply_screen_name</literal>, <literal>reply_tweet_id</literal> and such fields in the JSON record so users can follow the conversation (as you can see, they’re otherwise <literal>null</literal>). Where user A replies to user B, let’s emit A and B separated by a tab:<footnote>
          <para>In practice, we of course use numeric IDs and not screen names, but it’s easier to follow along with screen names. In order to keep the graph-theory discussion general, I’m going to play loose with some details and leave out various janitorial details of loading and running.</para>
        </footnote></para>
      <programlisting>class ReplyGraphMapper &lt; LineStreamer
  def process(raw_tweet)
    tweet = Tweet.new(raw_tweet)
    if tweet.is_reply?
      emit [tweet.screen_name, tweet.reply_screen_name]
    end
  end
end</programlisting>
      <para>The mapper derives from <literal>LineStreamer</literal>, a Wukong class that calls its <literal>process</literal> method on each line as a single record. It handles all the routing; we only have to define that <literal>process</literal> method. In this case, we use the raw JSON record to create a tweet object. When that tweet is part of a conversation, we emit the respective user IDs as an edge. Here’s what the raw output will look like:</para>
      <screen><prompt>% </prompt><userinput>reply_graph_mapper --run raw_tweets.json a_replies_b.tsv</userinput>
mrflip          tom_e_white
wattsteve       josephkelly
mrflip          mza
nealrichter     tlipcon</screen>
      <para>You should read this as “a replies b”, and interpret it as a directed “out” edge: <literal>@wattsteve</literal> conveys social capital to <literal>@josephkelly</literal>. </para>
      <sect3>
        <title>Edge pairs</title>
        <para>This is the <firstterm>edge pairs</firstterm> representation of a network. It’s simple, and it gives an equal jumping-off point for in- or out- edges, but there’s some duplication of data. You can tell the same story from the node’s point of view (and save some disk space) by rolling up on the source node. In Pig, this is a simple GROUP BY. Load the file:</para>
        <programlisting>a_replies_b = LOAD 'a_replies_b' AS (src: chararray, dest:chararray);</programlisting>
        <para>Then find all edges out from each node by grouping on source:</para>
        <programlisting>replies_out = GROUP a_replies_b BY source;
DUMP replies_out</programlisting>
        <screen>(CMastication,{(esammer,CMastication),(peteskomoroch,CMastication),(peteskomoroch,CMastication),(peteskomoroch,CMastication),(esammer,CMastication),(esammer,CMastication),(ChrisDiehl,CMastication),(esammer,CMastication),(peteskomoroch,CMastication),(esammer,CMastication),(peteskomoroch,CMastication),(peteskomoroch,CMastication),(peteskomoroch,CMastication),(esammer,CMastication),(bradfordcross,CMastication),(peteskomoroch,CMastication)})
(ChrisDiehl,{(DataJunkie,ChrisDiehl),(DataJunkie,ChrisDiehl),(peteskomoroch,ChrisDiehl)})
(DataJunkie,{(CMastication,DataJunkie),(CMastication,DataJunkie),(nealrichter,DataJunkie),(peteskomoroch,DataJunkie),(mat_kelcey,DataJunkie),(CMastication,DataJunkie),(communicating,DataJunkie),(ChrisDiehl,DataJunkie),(bradfordcross,DataJunkie),(nealrichter,DataJunkie),(mat_kelcey,DataJunkie),(mat_kelcey,DataJunkie)})
(LusciousPear,{(bradfordcross,LusciousPear),(metcalfc,LusciousPear),(mikeolson,LusciousPear),(metcalfc,LusciousPear),(metcalfc,LusciousPear),(tlipcon,LusciousPear),(kevinweil,LusciousPear),(bradfordcross,LusciousPear),(bradfordcross,LusciousPear),(DataJunkie,LusciousPear),(esammer,LusciousPear)})
(bradfordcross,{(LusciousPear,bradfordcross),(CMastication,bradfordcross),(mrflip,bradfordcross),(LusciousPear,bradfordcross),(peteskomoroch,bradfordcross),(ogrisel,bradfordcross),(LusciousPear,bradfordcross),(DataJunkie,bradfordcross),(ogrisel,bradfordcross)})
(communicating,{(nealrichter,communicating),(DataJunkie,communicating),(ogrisel,communicating),(ogrisel,communicating)})
(cutting,{(tom_e_white,cutting)})
(esammer,{(CMastication,esammer),(CMastication,esammer),(mikeolson,esammer),(mikeolson,esammer),(jeromatron,esammer)})
(jeromatron,{(mrflip,jeromatron),(mrflip,jeromatron)})
(josephkelly,{(wattsteve,josephkelly)})
(kevinweil,{(tlipcon,kevinweil),(DataJunkie,kevinweil),(mikeolson,kevinweil),(LusciousPear,kevinweil),(tlipcon,kevinweil),(tlipcon,kevinweil),(DataJunkie,kevinweil),(mrflip,kevinweil),(LusciousPear,kevinweil)})
(metcalfc,{(nealrichter,metcalfc),(nealrichter,metcalfc),(nealrichter,metcalfc)})
(mikeolson,{(LusciousPear,mikeolson),(kevinweil,mikeolson),(LusciousPear,mikeolson),(tlipcon,mikeolson)})
(mndoci,{(mrflip,mndoci),(peteskomoroch,mndoci),(LusciousPear,mndoci),(mrflip,mndoci)})
(mrflip,{(LusciousPear,mrflip),(mndoci,mrflip),(mndoci,mrflip),(ogrisel,mrflip),(esammer,mrflip),(ogrisel,mrflip),(esammer,mrflip),(esammer,mrflip),(wattsteve,mrflip)})
(mza,{(mrflip,mza)})
(nealrichter,{(metcalfc,nealrichter),(DataJunkie,nealrichter),(peteskomoroch,nealrichter),(metcalfc,nealrichter)})
(ogrisel,{(mrflip,ogrisel),(bradfordcross,ogrisel),(mrflip,ogrisel)})
(peteskomoroch,{(CMastication,peteskomoroch),(esammer,peteskomoroch),(DataJunkie,peteskomoroch),(CMastication,peteskomoroch),(mndoci,peteskomoroch),(CMastication,peteskomoroch),(nealrichter,peteskomoroch),(nealrichter,peteskomoroch),(bradfordcross,peteskomoroch),(ChrisDiehl,peteskomoroch),(mrflip,peteskomoroch),(mrflip,peteskomoroch),(LusciousPear,peteskomoroch),(bradfordcross,peteskomoroch),(ChrisDiehl,peteskomoroch),(nealrichter,peteskomoroch),(CMastication,peteskomoroch),(mndoci,peteskomoroch)})
(tlipcon,{(mrflip,tlipcon),(LusciousPear,tlipcon),(LusciousPear,tlipcon),(nealrichter,tlipcon),(LusciousPear,tlipcon),(nealrichter,tlipcon),(mrflip,tlipcon),(kevinweil,tlipcon)})
(tom_e_white,{(mrflip,tom_e_white),(lenbust,tom_e_white)})</screen>
      </sect3>
      <sect3>
        <title>Degree</title>
        <para>A simple, useful measure of influence is the number of replies a user receives. In graph terms this is the <firstterm>degree</firstterm> (specifically, the <firstterm>in-degree</firstterm> since this is a directed graph). </para>
        <para>Pig’s nested FOREACH syntax lets us count the distinct incoming repliers (neighbor nodes) and the total incoming replies in one pass:<footnote>
            <para>Due to a pesky Hadoop implementation detail, the small size of the edge pair records may inefficiently force the mapper to spill early. If the jobtracker dashboard shows “spilled records” greatly exceeding “map output records,” see if bumping up the <literal>io.sort.record.percent</literal> configuration parameter helps performance:</para>
            <programlisting>PIG_OPTS="-Dio.sort.record.percent=0.25 -Dio.sort.mb=350" pig my_file.pig</programlisting>
          </footnote></para>
        <programlisting>a_replies_b = LOAD 'a_replies_b' AS (src: chararray, dest:chararray);
replies_in = GROUP a_replies_b BY dest; -- group on dest to get in-links
DUMP replies_in
replies_in_degree  = FOREACH replies_in {
  nbrs = DISTINCT a_replies_b.src;
  GENERATE group, COUNT(nbrs), COUNT(a_replies_b);
};
DUMP replies_in_degree</programlisting>
        <screen>(mza,1L,1L)
(mndoci,3L,4L)
(mrflip,5L,9L)
(cutting,1L,1L)
(esammer,3L,5L)
(ogrisel,2L,3L)
(tlipcon,4L,8L)
(metcalfc,1L,3L)
(kevinweil,5L,9L)
(mikeolson,3L,4L)
(ChrisDiehl,2L,3L)
(DataJunkie,7L,12L)
(jeromatron,1L,2L)
(josephkelly,1L,1L)
(nealrichter,3L,4L)
(tom_e_white,2L,2L)
(CMastication,4L,16L)
(LusciousPear,7L,11L)
(bradfordcross,6L,9L)
(communicating,3L,4L)
(peteskomoroch,9L,18L)</screen>
        <para>This shows that <literal>@mrflip</literal>, for example, has five neighbors and 9 incoming replies.</para>
        <para>In Twitter, the in-degree can vary wildly. Most nodes have very few edges, but a few celebrities—<literal>@THE_REAL_SHAQ</literal> (basketball star Shaquille O’Neill) and <literal>@sockington</literal> (a fictional cat)—have millions. By contrast, almost every intersection on a road map is 4-way.<footnote>
            <para>The largest outlier that comes to mind is the famous "Magic Roundabout" in Swindon, England, with degree 10, <ulink
                url="http://en.wikipedia.org/wiki/Magic_Roundabout_%28Swindon%29"/>.</para>
          </footnote> This wild variation in degree (<firstterm>skewness</firstterm>) on the social graph has important ramifications for how you process such graphs—more later.</para>
      </sect3>
    </sect2>
    <sect2>
      <title>Symmetric Links</title>
      <para>On Twitter, millions of people have given <literal>@THE_REAL_SHAQ</literal> a shout-out; understandably, he has not reciprocated with millions of replies. As the graph shows, I frequently converse with <literal>@mndoci</literal><footnote>
          <para>Deepak Singh, open data advocate and bizdev manager of the Amazon AWS cloud.</para>
        </footnote>, making ours a <firstterm>symmetric link</firstterm>. This accurately reflects the fact that I have more in common with <literal>@mndoci</literal> than with <literal>@THE_REAL_SHAQ</literal>.</para>
      <para>One line of reasoning says to take the edges in <literal>A Replies B</literal> that are also in <literal>A ReplyFrom B</literal>. We can do that set intersection with an inner self-join:</para>
      <programlisting>-- out links
a_replies_b  = LOAD 'a_replies_b.tsv' AS (src:chararray, dest:chararray);
-- in links: reverse each edge
b_replies_a = FOREACH a_replies_b GENERATE dest AS user_a, src AS user_b;
-- symmetric edges are in both sets
a_symmetric_b_j = JOIN a_replies_b BY (src, dest), b_replies_a
  BY (user_a, user_b);</programlisting>
      <para>However, this sends two copies of the edge-pairs list to the reduce phase, doubling the memory required. We can do better by noticing that from a node’s point of view, a symmetric link is equivalent to one out- and one in-edge. Make the graph undirected by putting the node with lowest sort order in the first slot—but preserve the direction as a piece of edge metadata. </para>
      <programlisting>a_replies_b    = LOAD 'a_replies_b.tsv' AS (src: chararray, dest:chararray);
a_b_relations  = FOREACH a_replies_b GENERATE
  ((src &lt;= dest) ? src  : dest) AS user_a,
  ((src &lt;= dest) ? dest : src)  AS user_b,
  ((src &lt;= dest) ? 1 : 0)       AS a_re_b:int,
  ((src &lt;= dest) ? 0 : 1)       AS b_re_a:int;
DUMP a_b_relations</programlisting>
      <screen>(mrflip,tom_e_white,1,0)
(josephkelly,wattsteve,0,1)
(mrflip,mza,1,0)
(nealrichter,tlipcon,0,1)</screen>
      <para>Now gather all edges for each node pair together, and check for symmetry:</para>
      <programlisting>a_b_relations_g   = GROUP a_b_relations BY (user_a, user_b);
a_symmetric_b_all = FOREACH a_b_relations_g GENERATE 
  group.user_a AS user_a, 
  group.user_b AS user_b,
  ( ((SUM(a_b_relations.a_re_b) > 0) AND (SUM(a_b_relations.b_re_a) > 0)) ? 1 : 0)
    AS is_symmetric:int;
DUMP a_symmetric_b</programlisting>
      <screen>(mrflip,tom_e_white,1)
(mrflip,mza,0)
(josephkelly,wattsteve,0)
(nealrichter,tlipcon,1)
...</screen>
      <programlisting>a_symmetric_b = FILTER a_symmetric_b_all BY (is_symmetric == 1);
STORE a_symmetric_b INTO 'a_symmetric_b.tsv';</programlisting>
      <para>Here’s a portion of the output, showing that <literal>@mrflip</literal> and <literal>@tom_e_white</literal> have a symmetric link:</para>
      <screen>(mrflip,tom_e_white,1)
(nealrichter,tlipcon,1)
...</screen>
    </sect2>
    <sect2>
      <title>Community Extraction</title>
      <para>So far we’ve generated a node measure (in-degree) and an edge measure (symmetric link identification). Let’s move out one step and look at a neighborhood measure: how many of a given person’s friends are friends with each other? Along the way, we’ll produce the edge set for a visualization like the one above.</para>
      <sect3>
        <title>Get neighbors</title>
        <para>Choose a seed node. First round up the seed’s neighbors:</para>
        <programlisting>a_replies_b    = LOAD 'a_replies_b.tsv' AS (src: chararray, dest:chararray);
-- Extract edges that originate or terminate on the seed
n0_edges = FILTER a_replies_b BY (src == 'hadoop') OR (dest == 'hadoop');
-- Choose the node in each pair that *isn't* our seed:
n1_nodes_all = FOREACH n0_edges GENERATE ((src == 'hadoop') ? dest : src)
  AS screen_name;
n1_nodes    = DISTINCT n1_nodes_all;
DUMP n1_nodes</programlisting>
        <para>Now intersect the set of neighbors with the set of starting nodes to find all edges originating in <literal>n1_nodes</literal>:</para>
        <programlisting>n1_edges_left_j    = JOIN a_replies_b BY src, n1_nodes
  BY screen_name USING 'replicated';
n1_edges_left      = FOREACH n1_edges_left_j GENERATE src, dest;</programlisting>
        <para>Our copy of the graph has more than 1 billion edges, far too large to fit in memory. On the other hand, the neighbor count for a single user rarely exceeds a couple million, which fits easily in memory. Including <literal>USING 'replicated'</literal> in the JOIN command instructs Pig to do a map-side join (also called a <firstterm>fragment replicate join</firstterm>). Pig holds the <literal>n0_nodes</literal> relation in memory as a lookup table, and streams the full edge list past. Whenever the join condition is met—<literal>user_a</literal> is in the <literal>n0_nodes</literal> lookup table—it produces output. No reduce step makes for an enormous speedup!</para>
        <para>Finally, take all the edges out from {} and retain only those ending in to {Nbrs}.</para>
        <programlisting>-- Among those edges, find those that terminate in n1_nodes as well
n1_edges_j = JOIN n1_edges_left BY dest, n1_nodes
  BY screen_name USING 'replicated';
n1_edges    = FOREACH n1_edges_j GENERATE src, dest;
DUMP n1_edges</programlisting>
        <screen>(mrflip,tom_e_white)
(mrflip,mza)
(wattsteve,josephkelly)
(nealrichter,tlipcon)
(bradfordcross,lusciouspear)
(mrflip,jeromatron)
(mndoci,mrflip)
(nealrichter,datajunkie)</screen>
      </sect3>
      <sect3>
        <title>Community metrics and the 1 billion x 1 billion problem</title>
        <para><xref linkend="BigDataTwitterCommunity"
            /> displays the community extracted using <literal>@hadoop</literal>, <literal
            >@cloudera</literal> and <literal
            >@infochimps</literal> as seeds. As you can see, the big data community is very interconnected. The link neighborhood of a celebrity such as <literal
            >@THE_REAL_SHAQ</literal> is far more sparse.</para>
        <figure id="BigDataTwitterCommunity">
          <title>Big data community on Twitter</title>
          <mediaobject>
            <imageobject>
              <imagedata fileref="diagrams/n1atsigns2.png" format="PNG"/>
            </imageobject>
          </mediaobject>
        </figure>
        <para>We can characterize this using the <firstterm>clustering coefficient</firstterm>: the number of <literal>n1_edges</literal> to the maximum number of possible <literal>n1_edges</literal>. It ranges from zero (no neighbor links to any other neighbor) to one (every neighbor links to every other neighbor). A high clustering coefficient indicates a cohesive community. A low clustering coefficient could indicate widely-dispersed interest (as it does with <literal>@THE_REAL_SHAQ</literal>), or it could indicate the kind of inorganic community that a spam account would engender.</para>
        <para>Don’t try to recklessly generalize the calculation above to the full dataset. Remember the wide variation in node degree on the social graph discussed above? This skewness leads to an explosion of data—pop star <literal>@britneyspears</literal> (5.2M followers, 420k following as of July 2010) or <literal>@WholeFoods</literal> (1.7M followers, 600k following) will each generate trillions of entries. What’s worse, almost all of these will be thrown away: as just argued, the clustering coefficient for celebrities is very low! There is a very elegant way to do this on the full graph<footnote>
            <para>See <ulink url="http://www.slideshare.net/ydn/3-xxl-graphalgohadoopsummit2010"
                />, one of many fine tricks by Jake Hofman (<literal
                >@jakehofman</literal>) and Sergei Vassilvitskii (<literal
              >@vsergei</literal>) of Yahoo! Research.</para>
          </footnote>, but, if you’re willing to assume that <literal>@britneyspears</literal> isn’t <emphasis
            role="italic"
          >really</emphasis> friends with 420,000 people, you can still do a reasonable job. Just weight each edge (by number of replies, whether it’s symmetric, and so on) and set limits on the number of links from any node.</para>
        <para>
        </para>
        <para role="right">—Philip (flip) Kromer</para>
      </sect3>
    </sect2>
  </sect1>
</chapter>
